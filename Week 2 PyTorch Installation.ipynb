{"cells": [{"metadata": {}, "cell_type": "code", "source": "!pip install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp27-cp27mu-linux_x86_64.whl \n!pip install torchvision", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "\u001b[31mERROR: torch-0.3.0.post4-cp27-cp27mu-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\nCollecting torchvision\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/dc/4a939cfbd38398f4765f712576df21425241020bfccc200af76d19088533/torchvision-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (5.9MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5.9MB 3.8MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchvision) (5.4.1)\nRequirement already satisfied: numpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchvision) (1.15.4)\nCollecting torch==1.6.0 (from torchvision)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/53/914885a93a44b96c0dd1c36f36ff10afe341f091230aad68f7228d61db1e/torch-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 748.8MB 50kB/s s eta 0:00:01     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                  | 319.8MB 38.8MB/s eta 0:00:12     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                 | 352.9MB 41.1MB/s eta 0:00:10MB/s eta 0:00:04\n\u001b[?25hRequirement already satisfied: future in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torch==1.6.0->torchvision) (0.17.1)\nInstalling collected packages: torch, torchvision\nSuccessfully installed torch-1.6.0 torchvision-0.7.0\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import torch\nimport torch.autograd as autograd \nimport torch.nn as nn \nimport torch.optim as optim \n\ntorch.manual_seed(123)\n", "execution_count": 2, "outputs": [{"output_type": "execute_result", "execution_count": 2, "data": {"text/plain": "<torch._C.Generator at 0x7fdcf03ea288>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "v = [1, 2, 3]\nprint(type(v))\nprint(v)", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "<class 'list'>\n[1, 2, 3]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "v_tensor = torch.Tensor(v)\nprint(v_tensor)", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "tensor([1., 2., 3.])\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "mx = [[10, 20, 30], [40, 50, 60]]\nprint(mx)", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "[[10, 20, 30], [40, 50, 60]]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "mx_tesnor = torch.Tensor(mx)\nprint(mx_tesnor)", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "tensor([[10., 20., 30.],\n        [40., 50., 60.]])\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "mx2 = [[[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]]\nprint(mx2)", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "[[[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "mx2_tensor = torch.Tensor(mx2)\nprint(mx2_tensor)", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "tensor([[[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.],\n         [ 7.,  8.,  9.],\n         [10., 11., 12.]]])\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "mx3_tensor = torch.randn((4, 3, 3, 3))\nmx3_tensor.shape\nprint(mx3_tensor)", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "tensor([[[[ 3.3737e-01, -1.7778e-01, -3.0353e-01],\n          [-5.8801e-01,  3.4861e-01,  6.6034e-01],\n          [-2.1964e-01, -3.7917e-01,  7.6711e-01]],\n\n         [[-1.1925e+00,  6.9835e-01, -1.4097e+00],\n          [ 1.7938e-01,  1.8951e+00,  4.9545e-01],\n          [ 2.6920e-01, -7.7020e-02, -1.0205e+00]],\n\n         [[-1.6896e-01,  9.1776e-01,  1.5810e+00],\n          [ 1.3010e+00,  1.2753e+00, -2.0095e-01],\n          [ 4.9647e-01, -1.5723e+00,  9.6657e-01]]],\n\n\n        [[[-1.1481e+00, -1.1589e+00,  3.2547e-01],\n          [-6.3151e-01, -2.8400e+00, -1.3250e+00],\n          [ 1.7843e-01, -2.1338e+00,  1.0524e+00]],\n\n         [[-3.8848e-01, -9.3435e-01, -4.9914e-01],\n          [-1.0867e+00,  8.8054e-01,  1.5542e+00],\n          [ 6.2662e-01, -1.7549e-01,  9.8284e-02]],\n\n         [[-9.3507e-02,  2.6621e-01, -5.8504e-01],\n          [ 8.7684e-01,  1.6221e+00, -1.4779e+00],\n          [ 1.1331e+00, -1.2203e+00,  1.3139e+00]]],\n\n\n        [[[ 1.0533e+00,  1.3881e-01,  2.2473e+00],\n          [-8.0364e-01, -2.8084e-01,  7.6968e-01],\n          [-6.5956e-01, -7.9793e-01,  1.8383e-01]],\n\n         [[ 2.2935e-01,  5.1463e-01,  9.9376e-01],\n          [-2.5873e-01, -1.0826e+00, -4.4382e-02],\n          [ 1.6236e+00, -2.3229e+00,  1.0878e+00]],\n\n         [[ 6.7155e-01,  6.9330e-01, -9.4872e-01],\n          [-7.6507e-02, -1.5264e-01,  1.1674e-01],\n          [ 4.4026e-01, -1.4465e+00,  2.5529e-01]]],\n\n\n        [[[-5.4963e-01,  1.0042e+00,  8.2723e-01],\n          [-3.9481e-01,  4.8923e-01, -2.1681e-01],\n          [-1.7472e+00, -1.6025e+00, -1.0764e+00]],\n\n         [[ 9.0315e-01, -7.2184e-01,  1.2311e+00],\n          [-1.0973e+00, -9.6690e-01,  6.7125e-01],\n          [-9.4053e-01, -4.6806e-01,  1.0322e+00]],\n\n         [[-2.8300e-01,  1.1124e+00, -4.1684e-01],\n          [-1.7106e+00, -3.2902e-01,  1.3966e+00],\n          [-9.9491e-01, -1.5822e-03,  1.2471e+00]]]])\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "v = [1, 2, 3]\nprint(type(v))\nv_tensor = torch.Tensor(v)\nprint(v_tensor)\nmx = [[10, 20, 30], [40, 50, 60]]\nmx_tesnor = torch.Tensor(mx)\nprint(mx_tesnor)\nmx2 = [[[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]]\nmx2_tensor = torch.Tensor(mx2)\nprint(mx2_tensor)\nmx3_tensor = torch.randn((4, 3, 3, 3))\nmx3_tensor.shape\nprint(mx3_tensor)", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "<class 'list'>\ntensor([1., 2., 3.])\ntensor([[10., 20., 30.],\n        [40., 50., 60.]])\ntensor([[[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.],\n         [ 7.,  8.,  9.],\n         [10., 11., 12.]]])\ntensor([[[[-2.7202,  0.5421, -1.1541],\n          [ 0.7763, -0.2582, -2.0407],\n          [-0.8016, -0.8183, -0.0480]],\n\n         [[ 0.5349,  1.1031,  1.3334],\n          [-1.4053, -0.5922, -0.2548],\n          [ 1.1517,  0.8138,  0.6532]],\n\n         [[ 0.6557, -1.4056, -1.2743],\n          [ 0.4513, -0.2280,  0.9224],\n          [ 0.8566,  0.6465,  1.2782]]],\n\n\n        [[[ 2.5501, -0.3018, -0.6703],\n          [-0.6171, -0.8334,  0.5663],\n          [ 1.0306, -0.3047,  1.6873]],\n\n         [[ 0.6851,  2.0024, -0.5469],\n          [ 1.6014, -0.3016, -0.7074],\n          [-0.1465, -0.4943, -1.1766]],\n\n         [[-2.0524,  0.1132,  1.4353],\n          [-1.1454, -1.3316,  0.2230],\n          [ 0.6463,  0.1538, -0.4452]]],\n\n\n        [[[ 0.5503,  0.0658,  0.2225],\n          [-0.1689, -0.5455,  0.2487],\n          [ 0.1343,  0.7662,  2.2760]],\n\n         [[-1.3255, -1.0590,  0.0801],\n          [ 0.3531, -0.1207, -0.9797],\n          [-2.1126, -0.2721, -0.3510]],\n\n         [[-1.6483,  0.1536, -0.1807],\n          [-0.1086,  1.1721, -0.4372],\n          [-0.4053,  0.7086, -0.1346]]],\n\n\n        [[[ 0.4680, -0.7952, -0.9178],\n          [-0.0673,  0.2467, -0.9392],\n          [-1.0448, -0.4698,  1.0866]],\n\n         [[-0.8892,  0.7647,  0.0526],\n          [-1.1892,  0.6751, -0.5757],\n          [ 1.0949,  1.1196,  0.1306]],\n\n         [[-0.2589, -0.4780,  0.7995],\n          [ 0.9905, -0.0730, -1.0638],\n          [-0.3050,  0.1267,  1.6921]]]])\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "mx4 = [[[[10, 20, 30, 40, 50], [60, 70, 80, 90, 100], [110, 120, 130, 140, 150], [160, 170, 180, 190, 200]]]]\nprint(mx4)\nmx4_Tensor = torch.Tensor(mx4)\nprint(mx4_Tensor)", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "[[[[10, 20, 30, 40, 50], [60, 70, 80, 90, 100], [110, 120, 130, 140, 150], [160, 170, 180, 190, 200]]]]\ntensor([[[[ 10.,  20.,  30.,  40.,  50.],\n          [ 60.,  70.,  80.,  90., 100.],\n          [110., 120., 130., 140., 150.],\n          [160., 170., 180., 190., 200.]]]])\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "mx4Randn.shape\nprint(mx4Randn.shape)", "execution_count": 12, "outputs": [{"output_type": "error", "ename": "NameError", "evalue": "name 'mx4Randn' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-12-69d84288151a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmx4Randn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmx4Randn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mNameError\u001b[0m: name 'mx4Randn' is not defined"]}]}, {"metadata": {}, "cell_type": "code", "source": "mx4Randn = torch.randn(10, 20, 30, 40, 50)\nmx4Randn.shape\nprint(mx4Randn.shape)\nprint(mx4Randn)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "v = v_tensor[0]\nprint(v)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "v1 = v_tensor[1]\nprint(v1)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "m = (mx4_Tensor[0])\nprint(m)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "m_tensor = torch.randn((6, 3, 28, 28))\nprint(m_tensor)", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "tensor([[[[-8.4548e-01,  1.0481e+00,  9.2213e-01,  ...,  1.4561e+00,\n            6.6460e-01,  2.3805e+00],\n          [-8.9080e-02,  1.7927e-01,  4.6490e-01,  ...,  2.4183e-01,\n           -1.5392e+00, -3.5215e-02],\n          [-1.2689e+00,  6.5890e-01,  4.9074e-01,  ..., -7.1490e-01,\n           -1.1279e+00, -6.2128e-01],\n          ...,\n          [ 2.4861e-01, -1.1363e+00,  1.8714e+00,  ..., -4.4709e-01,\n            1.3153e+00, -1.1690e+00],\n          [ 9.6547e-01, -4.4502e-01,  1.9157e-02,  ..., -1.7191e+00,\n           -5.4873e-01,  1.5415e-02],\n          [-3.5682e-01, -1.4155e+00, -1.1469e+00,  ..., -1.4771e+00,\n            4.4270e-01, -5.8072e-01]],\n\n         [[-8.4435e-01,  3.9567e-01, -3.1204e-01,  ..., -3.3997e-01,\n            7.5383e-01, -2.1446e+00],\n          [ 2.2980e+00, -9.1292e-02,  9.6210e-01,  ..., -1.8117e-01,\n           -1.3202e+00, -1.1225e-02],\n          [ 2.1616e-01,  9.3441e-02, -4.9832e-01,  ..., -9.2589e-01,\n           -1.4909e-01,  5.3121e-01],\n          ...,\n          [ 2.1649e-01,  1.4064e+00,  1.3200e+00,  ...,  7.9161e-01,\n           -2.4696e-01,  6.9572e-01],\n          [ 8.1390e-01, -4.9829e-01, -6.9582e-03,  ...,  3.6607e-01,\n            1.0526e+00,  1.2995e+00],\n          [-8.8753e-01, -1.2690e+00, -6.6160e-01,  ...,  1.3618e+00,\n           -2.3022e-01, -5.0011e-01]],\n\n         [[-1.0364e+00,  1.2532e+00,  6.4281e-01,  ...,  1.0343e+00,\n           -3.5379e-01,  8.9772e-01],\n          [ 6.6737e-01,  8.4843e-01, -2.7813e-01,  ...,  1.1384e+00,\n            2.6715e-01, -7.5254e-02],\n          [ 6.3695e-01, -2.0795e+00, -3.5005e-01,  ..., -2.9009e+00,\n            4.6074e-01,  2.0136e-01],\n          ...,\n          [ 8.2683e-01,  7.8314e-01, -1.2980e+00,  ..., -1.5985e+00,\n            6.2656e-03,  1.1274e-02],\n          [ 2.1273e+00, -1.1888e+00, -9.4736e-01,  ...,  7.5871e-01,\n            4.8843e-01, -6.8312e-01],\n          [-1.3079e+00, -6.7665e-01,  1.1539e+00,  ..., -7.8402e-02,\n           -5.5001e-01,  8.7644e-01]]],\n\n\n        [[[-1.9020e+00, -6.2668e-02, -2.8073e-01,  ..., -1.3026e+00,\n           -2.3961e-01, -2.6992e+00],\n          [-1.4146e-01,  2.9102e-04, -1.2296e+00,  ..., -9.8973e-01,\n           -5.8949e-01, -8.2926e-01],\n          [-6.8276e-01,  6.0078e-01,  7.5828e-01,  ...,  1.2554e+00,\n            1.5253e+00,  1.4508e+00],\n          ...,\n          [-9.5699e-01,  1.2729e-01,  2.7087e-01,  ...,  1.0548e+00,\n            1.0641e+00,  2.0403e+00],\n          [-2.3547e-01,  1.5194e+00,  1.1178e+00,  ...,  2.8006e-01,\n            2.7662e-01,  1.6901e+00],\n          [-1.8815e-01, -1.1330e+00, -6.9611e-01,  ..., -2.0945e+00,\n           -4.2642e-01, -4.2012e-01]],\n\n         [[-1.2345e-01,  1.5984e+00,  1.1405e+00,  ..., -2.0018e-02,\n           -8.4097e-01,  2.0086e-01],\n          [-5.1172e-02,  4.2363e-01, -3.5763e-01,  ..., -1.2522e-01,\n            3.5331e-01, -2.2059e+00],\n          [-2.5309e-01,  5.5200e-02,  2.4059e-01,  ..., -1.2881e+00,\n            8.9376e-02, -2.6563e-01],\n          ...,\n          [ 1.0424e+00,  1.9440e-02, -1.4102e+00,  ...,  4.1784e-01,\n           -1.2950e+00, -6.6526e-01],\n          [ 1.3466e+00,  1.7084e+00,  5.5872e-01,  ...,  1.5133e-01,\n            4.3124e-01, -1.8056e+00],\n          [ 2.2072e+00,  6.3929e-01, -2.4038e-01,  ...,  1.5897e+00,\n           -9.7251e-01,  6.3375e-01]],\n\n         [[ 3.9719e-01,  1.9071e+00, -1.6623e+00,  ...,  5.0491e-01,\n            9.2878e-02, -1.0155e+00],\n          [-1.3429e+00,  9.2866e-01,  2.7979e-02,  ..., -4.3780e-01,\n            8.8632e-01,  6.5330e-02],\n          [-6.1876e-01, -8.6347e-01,  4.3697e-01,  ...,  6.2108e-01,\n            8.9121e-01,  8.3024e-01],\n          ...,\n          [ 2.5036e-01, -1.5727e-01,  9.5019e-01,  ...,  1.8946e-02,\n           -1.3160e+00,  1.1586e+00],\n          [-1.2547e+00,  3.3854e-01,  4.4420e-01,  ..., -1.3483e+00,\n            2.4106e-02, -5.7490e-01],\n          [ 1.4831e+00,  7.5988e-01,  7.2493e-01,  ..., -6.5006e-01,\n            4.6959e-02,  2.1851e-01]]],\n\n\n        [[[-1.8077e-01,  1.4236e+00,  5.8489e-01,  ..., -2.1797e+00,\n            2.1646e+00, -5.6821e-01],\n          [ 1.1692e+00, -5.3133e-01,  2.4394e+00,  ...,  7.3814e-02,\n           -4.1646e-01, -1.0140e+00],\n          [ 8.5610e-02,  3.1419e-01, -3.7144e-01,  ...,  3.9496e-03,\n           -5.5692e-01,  1.2083e-01],\n          ...,\n          [-5.2333e-01, -6.5431e-01, -9.6304e-01,  ..., -1.7825e+00,\n           -8.2090e-01,  8.6365e-01],\n          [-1.1667e+00,  7.3070e-01, -3.2300e-01,  ...,  1.3469e+00,\n           -4.2677e-01,  1.2332e-01],\n          [ 2.1079e-01, -1.6862e-01,  2.0537e-01,  ..., -1.4669e+00,\n            4.7748e-01,  8.2145e-01]],\n\n         [[ 7.3720e-02,  1.9660e-01, -9.9870e-01,  ...,  1.3425e+00,\n            1.2191e+00, -5.3195e-01],\n          [-3.9512e-02, -8.2698e-01, -5.5850e-01,  ..., -1.6419e+00,\n            3.1729e-01, -3.7979e-01],\n          [-8.1401e-01,  1.2310e-01,  6.2099e-01,  ...,  6.6002e-01,\n           -1.1555e-01,  8.6763e-01],\n          ...,\n          [ 8.6197e-01,  1.5738e-01,  1.0329e+00,  ..., -1.0133e+00,\n            1.0645e+00,  2.6245e+00],\n          [ 1.7615e-01, -3.7219e-01, -7.5810e-01,  ..., -7.7864e-01,\n            1.8867e+00, -8.1354e-01],\n          [ 2.7414e-01, -5.6145e-01, -6.2794e-01,  ...,  1.3222e+00,\n            2.6589e-01,  6.4872e-01]],\n\n         [[-4.4208e-01, -3.3650e-02,  3.0279e-02,  ..., -1.6591e+00,\n            1.3659e+00, -2.2756e-01],\n          [ 1.1281e+00,  5.6964e-01,  7.4995e-01,  ..., -7.8593e-01,\n           -1.7399e-01,  8.6940e-01],\n          [-8.4867e-01,  4.6664e-01,  2.6543e-01,  ..., -1.3163e-02,\n           -2.1691e+00, -3.8908e-01],\n          ...,\n          [-7.3804e-01,  1.4157e+00,  1.0477e+00,  ..., -9.0315e-01,\n            7.4902e-01,  1.1452e+00],\n          [ 9.9426e-01, -3.0900e-01, -1.0275e+00,  ...,  2.4795e-01,\n            1.6401e+00,  2.0499e+00],\n          [-1.7460e-01,  5.9335e-01,  6.4854e-01,  ..., -9.2225e-01,\n            2.0120e-01,  6.5423e-01]]],\n\n\n        [[[ 8.1038e-01,  9.8330e-01,  5.7373e-01,  ..., -2.3926e+00,\n            7.0662e-01,  4.6899e-01],\n          [ 1.0919e+00,  2.1746e-01,  4.4627e-01,  ...,  4.4714e-01,\n           -7.5079e-01,  1.3654e+00],\n          [-9.6184e-03, -2.2962e-01,  9.7498e-01,  ...,  7.1328e-01,\n           -5.2006e-01,  1.1059e+00],\n          ...,\n          [ 9.0320e-01,  9.6817e-01,  7.4513e-01,  ..., -8.8894e-01,\n            2.5229e-01, -2.8118e-01],\n          [ 1.0297e-01,  1.1220e+00, -5.1647e-01,  ..., -1.0421e+00,\n            1.6487e+00,  2.0011e-01],\n          [ 1.2761e-02, -4.6170e-01, -4.3705e-01,  ..., -1.1758e-01,\n           -5.3509e-01, -3.5536e-01]],\n\n         [[-6.3611e-01,  3.2523e-01,  1.3073e+00,  ...,  3.6079e-01,\n            3.0222e-01, -1.9292e+00],\n          [ 1.1755e+00,  5.6070e-02,  8.6216e-01,  ...,  2.3398e-01,\n            7.3952e-01,  2.5222e+00],\n          [-3.6657e-01, -2.0532e-01, -3.0216e-01,  ...,  6.0277e-01,\n            8.3257e-02,  6.7195e-01],\n          ...,\n          [ 1.3801e+00, -8.1520e-01, -7.0350e-01,  ..., -1.3603e+00,\n            3.2151e-01, -3.2034e-01],\n          [ 2.3827e+00,  8.4246e-01,  9.4327e-01,  ..., -4.9838e-01,\n           -2.9728e-01,  8.5762e-02],\n          [-3.6023e-01,  5.6515e-01, -1.1868e+00,  ...,  5.3324e-01,\n            9.7427e-02, -2.8822e-01]],\n\n         [[-1.1664e+00,  1.8951e+00, -9.0784e-01,  ...,  3.2584e-01,\n            1.9678e-01, -2.3591e+00],\n          [ 5.5964e-01,  3.4819e-01,  7.5693e-01,  ...,  2.8579e+00,\n            8.1869e-01,  1.8255e+00],\n          [ 3.0125e+00, -3.0318e-01,  7.1868e-01,  ...,  1.3925e-01,\n           -6.2680e-01,  1.5238e-01],\n          ...,\n          [ 5.9697e-01,  1.9455e-01, -2.4799e-01,  ...,  3.9894e-02,\n            1.0500e+00,  4.1417e-01],\n          [-5.7081e-01, -4.4410e-01, -6.3549e-01,  ...,  7.5095e-01,\n           -1.9504e-01,  7.7334e-01],\n          [-1.2171e+00,  8.3037e-01, -1.5329e+00,  ...,  5.0970e-01,\n            9.9946e-01, -3.7224e-01]]],\n\n\n        [[[ 4.6727e-02, -1.1909e+00,  8.1260e-01,  ...,  9.5642e-01,\n            3.9828e-01, -6.1771e-01],\n          [ 9.5704e-01,  8.9609e-02,  1.3356e+00,  ..., -1.1978e+00,\n           -2.5244e-01, -1.1025e+00],\n          [-1.3894e+00, -9.3428e-01,  7.2663e-01,  ..., -7.7294e-01,\n            7.2761e-02,  1.5439e+00],\n          ...,\n          [-2.3996e-01,  1.8623e-01,  5.6794e-01,  ...,  1.1699e+00,\n            5.8619e-01, -2.6103e+00],\n          [ 6.8947e-01, -7.2282e-01,  1.2903e-01,  ..., -1.9867e-01,\n            2.7796e-01,  3.7298e-02],\n          [-5.7272e-01, -1.4711e-01, -5.3536e-01,  ...,  9.9641e-01,\n            1.0172e+00, -1.1325e-02]],\n\n         [[-1.6780e-01, -1.0782e-01,  3.7157e-01,  ..., -9.7144e-01,\n            1.8506e-01,  5.5459e-01],\n          [ 2.0561e-01,  1.1003e+00,  1.6372e+00,  ..., -1.4229e+00,\n           -1.2377e-01,  1.7000e+00],\n          [-8.2607e-01, -8.6573e-01, -3.1631e-01,  ..., -1.5922e-01,\n           -5.0159e-01,  3.8123e-01],\n          ...,\n          [-2.7804e-01, -1.1926e+00, -9.7991e-01,  ..., -9.3080e-01,\n           -1.2647e+00, -4.0762e-01],\n          [ 9.6064e-01, -1.3874e+00, -5.1692e-01,  ...,  6.3301e-01,\n           -1.4398e+00,  1.4966e-01],\n          [ 1.7734e-01,  2.4234e+00, -2.8836e-01,  ..., -9.4366e-01,\n           -6.7023e-01, -4.0550e-01]],\n\n         [[ 1.5574e+00,  3.4717e-03,  4.7074e-01,  ...,  1.3354e+00,\n            2.0163e+00, -4.5949e-02],\n          [-5.9315e-01,  3.3705e-01,  8.2964e-01,  ...,  4.7922e-01,\n           -8.4268e-01, -7.4553e-01],\n          [-1.3539e+00, -8.5991e-02, -7.9336e-01,  ..., -1.9053e+00,\n            3.0223e-01, -2.5764e+00],\n          ...,\n          [-3.1540e-01,  2.4158e-01,  9.5116e-01,  ..., -4.9579e-02,\n            1.3635e+00, -1.2343e+00],\n          [-1.2743e+00, -3.0590e+00,  1.2976e+00,  ..., -2.4228e+00,\n           -7.2742e-01, -1.7089e+00],\n          [-6.5079e-01,  1.7140e+00, -1.0932e+00,  ..., -1.0652e+00,\n           -2.2299e+00, -4.8149e-01]]],\n\n\n        [[[-1.2520e+00,  1.5752e+00,  2.5533e-01,  ..., -5.2817e-02,\n           -1.0893e-01,  3.6656e-01],\n          [-2.4260e-02, -6.0048e-01, -1.5418e-01,  ..., -4.3674e-01,\n           -1.5795e-01,  1.7457e+00],\n          [-9.2917e-03,  5.9151e-01,  1.1073e+00,  ..., -5.3440e-02,\n            1.0780e+00,  1.2821e+00],\n          ...,\n          [-1.3599e+00, -2.2931e-01, -1.7412e+00,  ...,  5.4619e-01,\n            3.6539e-01,  2.8197e-01],\n          [-7.4025e-01, -5.9016e-01,  3.3804e-01,  ...,  4.4010e-01,\n            1.3703e+00, -6.5861e-02],\n          [-3.3157e-01,  9.2259e-01,  1.0229e+00,  ..., -1.1095e+00,\n            5.6017e-01,  7.9082e-01]],\n\n         [[ 9.4118e-01, -4.1574e-01, -3.6929e-01,  ..., -1.3866e+00,\n            5.5666e-01,  7.7526e-01],\n          [-2.2882e-02, -7.0887e-01, -1.0127e+00,  ...,  4.6957e-02,\n           -7.6120e-01, -1.4019e+00],\n          [-4.0821e-01, -7.4269e-01,  1.9747e+00,  ...,  1.2787e+00,\n            1.7002e+00, -1.1974e+00],\n          ...,\n          [-7.3885e-01,  4.2215e-01,  2.1272e+00,  ..., -8.3064e-01,\n           -1.5283e+00,  1.4827e-02],\n          [ 4.5768e-01,  3.8889e-01, -3.4112e-01,  ...,  9.6876e-01,\n           -1.5496e-01, -2.8182e-01],\n          [ 9.7829e-01,  1.8808e+00, -8.0664e-01,  ..., -3.3247e-01,\n            2.6759e-01, -2.8813e-02]],\n\n         [[-1.3485e+00,  2.3933e-01, -4.8308e-01,  ..., -4.2976e-01,\n           -4.2249e-01,  1.0770e+00],\n          [ 1.2725e+00,  7.4192e-01,  4.1164e-01,  ...,  1.1320e+00,\n            5.7308e-01,  1.6593e+00],\n          [-1.7342e+00,  1.8633e+00,  2.6756e+00,  ..., -3.3834e-01,\n           -7.7483e-01,  5.2673e-01],\n          ...,\n          [ 1.1450e+00, -4.9912e-02,  5.6179e-02,  ...,  2.1664e-02,\n           -8.9785e-01,  4.6250e-01],\n          [ 6.7545e-01,  6.9915e-01, -1.4964e+00,  ..., -1.3545e+00,\n            4.6897e-01,  3.3986e-01],\n          [-8.3906e-01,  6.1766e-01, -9.4308e-01,  ..., -1.0198e+00,\n            1.1710e+00,  8.3180e-01]]]])\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "m_tensor = torch.randn((5, 4, 4, 4))\nm_tensor[0]", "execution_count": 15, "outputs": [{"output_type": "execute_result", "execution_count": 15, "data": {"text/plain": "tensor([[[-0.6022,  1.1448, -1.2100,  0.7550],\n         [-0.8736,  1.0299, -0.2774,  1.1761],\n         [ 1.7400,  0.0871, -0.7604, -0.1946],\n         [ 1.4565,  0.0183,  0.4990,  0.9312]],\n\n        [[-0.5974,  0.9879,  0.8808, -0.5737],\n         [ 0.5387,  0.6455, -1.3289,  2.3954],\n         [ 1.1456, -0.2786, -0.9653,  0.5780],\n         [-0.5297, -0.4778, -1.7308,  0.5774]],\n\n        [[-0.5474,  1.1036, -0.5873, -1.5756],\n         [ 0.7006,  0.9885, -0.3619,  0.5669],\n         [ 1.0573,  2.6571, -0.8692, -1.6572],\n         [-1.0871, -0.7179, -1.3324, -1.1169]],\n\n        [[-1.9410,  2.1953,  1.8257,  0.4922],\n         [-0.3827,  0.5720,  0.9850,  1.0534],\n         [-0.1647,  1.5200,  0.1877,  0.6097],\n         [-0.2396,  1.2822,  0.1343, -0.5494]]])"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "x = torch.randn(4, 3)\ny = torch.randn(3, 4)", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "z = torch.cat([x, y], 1)\nprint(z)", "execution_count": 18, "outputs": [{"output_type": "error", "ename": "RuntimeError", "evalue": "Sizes of tensors must match except in dimension 1. Got 4 and 3 in dimension 0 (The offending index is 1)", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)", "\u001b[0;32m<ipython-input-18-efd99b3065e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Got 4 and 3 in dimension 0 (The offending index is 1)"]}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}